import torch
import torch.nn as nn
import torch.nn.functional as F
from torchsummary import summary
from PIL import Image
import numpy as np
import os



def load_dataset(fname=None):
    if fname is None:
        # Assume we are in the utils folder and get the absolute path to the
        # parent directory.
        fname = os.path.abspath(os.path.join(os.path.dirname(__file__),
                                             os.path.pardir))
        fname = os.path.join(fname, 'labels.csv')

    data = np.genfromtxt(fname, dtype=['|S19', '<f8', '|S4'], names=[
                         'path', 'probability', 'type'])
    image_fnames = np.char.decode(data['path'])
    probs = data['probability']
    types = np.char.decode(data['type'])

    def load_cell_image(fname):
        with Image.open(fname) as image:
            return np.asarray(image)

    dir = os.path.dirname(fname)

    images = np.array([load_cell_image(os.path.join(dir, fn))
                       for fn in image_fnames])

    return images, probs, types



class AlexNetCNN(nn.Module):
    def __init__(self):
        super(AlexNetCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0)
        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)

        
        self.conv2 = nn.Conv2d(96, 256, kernel_size=5, padding=2)
        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)

        
        self.conv3 = nn.Conv2d(256, 384, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(384, 384, kernel_size=3, padding=1)
        self.conv5 = nn.Conv2d(384, 256, kernel_size=3, padding=1)
        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)

      
        self.fc1 = nn.Linear(256 * 6 * 6, 4096)
        self.fc2 = nn.Linear(4096, 4096)
        self.fc3 = nn.Linear(4096, 4)
    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = F.relu(self.conv3(x))
        x = F.relu(self.conv4(x))
        x = self.pool3(F.relu(self.conv5(x)))

       

        x = x.view(-1, 256 * 6 * 6)

        
        x = F.relu(F.dropout(self.fc1(x), 0.5))
        x = F.relu(F.dropout(self.fc2(x), 0.5))

        x = self.fc3(x)
        

        return x


model = AlexNetCNN()



from google.colab import drive
drive.mount('/content/drive')
image_path = '/content/drive/My Drive/elpv-dataset-master'

import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from sklearn.model_selection import train_test_split
import pandas as pd
import matplotlib.pyplot as plt
class_indices = {
    0.0: 0,
    0.3333333333333333: 1,
    0.6666666666666666: 2,
    1.0: 3
}

class CellImagesDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.data_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.data_frame)

    def __getitem__(self, idx):
      img_name, probability = self.data_frame.iloc[idx, :].values
      img_name = img_name.strip()
      img_path = os.path.join(self.root_dir, img_name)
      image = Image.open(img_path)

      label = class_indices[probability]  # Convert probability to class index

      if self.transform:
          image = self.transform(image)

      return image, label
# Image transformations
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing with standard ImageNet means and stds
])
# Load the dataset
dataset = CellImagesDataset(csv_file='/content/drive/My Drive/elpv-dataset-master/labels.csv',
                            root_dir='/content/drive/My Drive/elpv-dataset-master/images',
                            transform=transform)

# Create a DataLoader
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)
train_size = int(0.7 * len(dataset))  # Using 70% for training
test_val_size = len(dataset) - train_size
val_size = int(0.5 * test_val_size)  # Splitting the remaining 30% equally for validation and test
test_size = test_val_size - val_size

train_dataset, test_val_dataset = torch.utils.data.random_split(dataset, [train_size, test_val_size])
val_dataset, test_dataset = torch.utils.data.random_split(test_val_dataset, [val_size, test_size])

# Dataloader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 10
train_losses, val_losses = [], []
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    train_losses.append(running_loss / len(train_loader))

    model.eval()
    val_running_loss = 0.0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_running_loss += loss.item()
    val_losses.append(val_running_loss / len(val_loader))
    
    print(f'Epoch {epoch+1}/{num_epochs} - Training Loss: {running_loss / len(train_loader):.4f}, Validation Loss: {val_running_loss / len(val_loader):.4f}')


# Plot the training and validation loss
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

